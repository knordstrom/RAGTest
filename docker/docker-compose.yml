services:
  weaviate:
    image: cr.weaviate.io/semitechnologies/weaviate:1.24.4
    ports:
    - 8080:8080
    - 50051:50051
  #  restart: on-failure:5
    environment:
      QUERY_DEFAULTS_LIMIT: 25
      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'
      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'
      ENABLE_MODULES: text2vec-transformers,reranker-transformers
      DEFAULT_VECTORIZER_MODULE: text2vec-transformers
      TRANSFORMERS_INFERENCE_API: http://t2v-transformers:8080
      RERANKER_INFERENCE_API: http://reranker-transformers:8080
      CLUSTER_HOSTNAME: 'weaviate-1'
  reranker-transformers:
    platform: linux/x86_64
    image: cr.weaviate.io/semitechnologies/reranker-transformers:cross-encoder-ms-marco-MiniLM-L-6-v2
    environment:
      ENABLE_CUDA: '0'
  t2v-transformers:  # Set the name of the inference container
    image: cr.weaviate.io/semitechnologies/transformers-inference:sentence-transformers-multi-qa-MiniLM-L6-cos-v1
    environment:
      ENABLE_CUDA: 0 
  neo4j:
    image: neo4j:5.22.0
    ports:
    - 7687:7687
    - 7474:7474
 #   restart: on-failure:5
    # volumes:
    #   - /var/lib/neo4j/data:/data
    environment:
      - NEO4JLABS_PLUGINS=["apoc"]
      - NEO4J_AUTH=${NEO4J_USERNAME}/${NEO4J_PASSWORD}
      - NEO4J_apoc_export_file_enabled=true 
      - NEO4J_apoc_import_file_enabled=true 
      - NEO4J_apoc_import_file_use__neo4j__config=true 
  zoo1:
    image: confluentinc/cp-zookeeper:7.3.2
    hostname: zoo1
    container_name: zoo1
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_SERVER_ID: 1
      ZOOKEEPER_SERVERS: zoo1:2888:3888

  kafka1:
    image: confluentinc/cp-kafka:7.3.2
    hostname: kafka1
    container_name: kafka1
    ports:
      - "9092:9092"
      - "29092:29092"
      - "9999:9999"
    environment:
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka1:19092,EXTERNAL://${DOCKER_HOST_IP:-127.0.0.1}:9092,DOCKER://host.docker.internal:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT,DOCKER:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_ZOOKEEPER_CONNECT: "zoo1:2181"
      KAFKA_BROKER_ID: 1
      KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_JMX_PORT: 9999
      KAFKA_JMX_HOSTNAME: ${DOCKER_HOST_IP:-127.0.0.1}
      KAFKA_AUTHORIZER_CLASS_NAME: kafka.security.authorizer.AclAuthorizer
      KAFKA_ALLOW_EVERYONE_IF_NO_ACL_FOUND: "true"
      KAFKA_AUTO_CREATE_TOPICS: "true"
    depends_on:
      - zoo1

  processor:
    image: context-processor:0.1.1
    environment:
      KAFKA_BROKER: "host.docker.internal:29092"
      KAFKA_TOPIC: "emails"
      PYTHONUNBUFFERED: 1
      VECTOR_DB_HOST: "docker-weaviate-1"
      VECTOR_DB_PORT: 8080
      NEO4J_DB_HOST: "docker-neo4j-1"
      NEO4J_DB_PORT: 7687
      NEO4J_USERNAME: "${NEO4J_USERNAME}"
      NEO4J_PASSWORD: "${NEO4J_PASSWORD}"
    depends_on:
      - kafka1
      - weaviate

  event_processor:
    image: event-processor:0.1.1
    environment:
      KAFKA_BROKER: "kafka1:29092"
      KAFKA_TOPIC: "calendar"
      PYTHONUNBUFFERED: 1
      NEO4J_DB_HOST: "docker-neo4j-1"
      NEO4J_DB_PORT: 7687
      NEO4J_USERNAME: "${NEO4J_USERNAME}"
      NEO4J_PASSWORD: "${NEO4J_PASSWORD}"
    depends_on:
      - kafka1
      - neo4j

  document_processor:
    image: document-processor:0.1.1
    environment:
      KAFKA_BROKER: "kafka1:29092"
      KAFKA_TOPIC: "documents"
      PYTHONUNBUFFERED: 1
      GROQ_API_KEY: "${GROQ_API_KEY}"
      VECTOR_DB_HOST: "docker-weaviate-1"
      VECTOR_DB_PORT: 8080
    depends_on:
      - kafka1
      - weaviate
  
  transcript_processor:
    image: transcript-processor:0.1.1
    environment:
      KAFKA_BROKER: "kafka1:29092"
      KAFKA_TOPIC: "transcripts"
      PYTHONUNBUFFERED: 1
      GROQ_API_KEY: "${GROQ_API_KEY}"
      VECTOR_DB_HOST: "docker-weaviate-1"
      VECTOR_DB_PORT: 8080
    depends_on:
      - kafka1
      - weaviate
  
  slack_processor:
    image: slack-processor:0.1.1
    environment:
      KAFKA_BROKER: "kafka1:29092"
      KAFKA_TOPIC: "slack"
      PYTHONUNBUFFERED: 1
      GROQ_API_KEY: "${GROQ_API_KEY}"
      VECTOR_DB_HOST: "docker-weaviate-1"
      VECTOR_DB_PORT: 8080
    depends_on:
      - kafka1
      - weaviate
      
  api:
    image: context-api:0.1.1
    ports:
      - "5010:5010"
      - "3127:3127"
    environment:
      KAFKA_BROKER: "kafka1:29092"
      KAFKA_TOPIC: "emails"
      PYTHONUNBUFFERED: 1
      VECTOR_DB_HOST: "docker-weaviate-1"
      VECTOR_DB_PORT: 8080
      NEO4J_DB_HOST: "docker-neo4j-1"
      NEO4J_URI: "docker-neo4j-1:7474"
      NEO4J_USERNAME: "${NEO4J_USERNAME}"
      NEO4J_PASSWORD: "${NEO4J_PASSWORD}"
      GROQ_API_KEY: "${GROQ_API_KEY}"
      GSUITE_CREDS_FILE: "${GSUITE_CREDS_FILE}"
    depends_on:
      - kafka1
      - weaviate
      - neo4j
  
  # This service runs the postgres DB used by dagster for run storage, schedule storage,
  # and event log storage.
  dagster_postgresql:
    image: postgres:11
    container_name: dagster_postgresql
    environment:
      POSTGRES_USER: "postgres_user"
      POSTGRES_PASSWORD: "postgres_password"
      POSTGRES_DB: "postgres_db"
    networks:
      - dagster_network

  # This service runs dagster-webserver, which loads your user code from the user code container.
  # Since our instance uses the QueuedRunCoordinator, any runs submitted from the webserver will be put on
  # a queue and later dequeued and launched by dagster-daemon.
  dagster_webserver:
    image: dagster
    entrypoint:
      - dagster-webserver
      - -h
      - "0.0.0.0"
      - -p
      - "3000"
      - -w
      - workspace.yaml
    container_name: dagster_webserver
    expose:
      - "3000"
    ports:
      - "3000:3000"
    environment:
      DAGSTER_POSTGRES_USER: "postgres_user"
      DAGSTER_POSTGRES_PASSWORD: "postgres_password"
      DAGSTER_POSTGRES_DB: "postgres_db"
    volumes: # Make docker client accessible, so we can terminate containers from the webserver
      - /var/run/docker.sock:/var/run/docker.sock
      - /tmp/io_manager_storage:/tmp/io_manager_storage
    networks:
      - dagster_network
    depends_on:
      - dagster_postgresql

  # This service runs the dagster-daemon process, which is responsible for taking runs
  # off of the queue and launching them, as well as creating runs from schedules or sensors.
  dagster_daemon:
    image: dagster
    entrypoint:
      - dagster-daemon
      - run
    container_name: dagster_daemon
    restart: on-failure
    environment:
      DAGSTER_POSTGRES_USER: "postgres_user"
      DAGSTER_POSTGRES_PASSWORD: "postgres_password"
      DAGSTER_POSTGRES_DB: "postgres_db"
      AWS_ACCESS_KEY_ID: "yourAWSKeyID"
      AWS_SECRET_ACCESS_KEY: "yourAWSSecretAccessKey"
      DATABASE_IP: "192.168.136.166"
      DATABASE_PORT: 5432
      DATABASE_USER: "etl_user"
      DATABASE_PASSWORD: "etl_password"
      DATABASE_NAME: "etl_db"
    volumes: # Make docker client accessible, so we can launch containers using host docker
      - /var/run/docker.sock:/var/run/docker.sock
      - /tmp/io_manager_storage:/tmp/io_manager_storage
    networks:
      - dagster_network
    depends_on:
      - dagster_postgresql

networks:
  dagster_network:
    driver: bridge
    name: dagster_network
